{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45168110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes:\n",
    "# GraphSAGE encoder\n",
    "# Drug+protein MLP fusion\n",
    "# Binary classifier\n",
    "# Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da64649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "from torch_geometric.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "import pandas as pd, torch, os\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class DrugTargetDataset(Dataset):\n",
    "    def __init__(self, pair_file, graph_dir, protein_csv):\n",
    "        self.pairs = pd.read_csv(pair_file)\n",
    "        self.graph_dir = graph_dir\n",
    "        self.protein_df = pd.read_csv(protein_csv).set_index(\"sequence_id\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.pairs.iloc[idx]\n",
    "        drug_id = row[\"drug_id\"]\n",
    "        target_id = row[\"target_id\"]\n",
    "        label = torch.tensor([row[\"label\"]], dtype=torch.float)\n",
    "\n",
    "        # Load graph\n",
    "        graph = torch.load(os.path.join(self.graph_dir, f\"{drug_id}.pt\"))\n",
    "\n",
    "        # Get protein embedding\n",
    "        protein_vec = torch.tensor(self.protein_df.loc[target_id].values, dtype=torch.float)\n",
    "\n",
    "        return graph, protein_vec, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model architecture with enhanced layers and dropout\n",
    "class DrugTargetModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, protein_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, hidden_dim)  # extra layer for better graph learning\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.lin1 = nn.Linear(hidden_dim + protein_dim, 128)\n",
    "        self.lin2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, graph, protein_vec, batch, return_logits=False):\n",
    "        x = F.relu(self.conv1(graph.x, graph.edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, graph.edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x, graph.edge_index))\n",
    "        x = global_mean_pool(x, batch)  # graph-level representation\n",
    "\n",
    "        x = torch.cat([x, protein_vec], dim=1)\n",
    "        x = self.dropout(F.relu(self.lin1(x)))\n",
    "        logits = self.lin2(x)\n",
    "        \n",
    "        # Return logits for BCEWithLogitsLoss or probabilities for evaluation\n",
    "        if return_logits:\n",
    "            return logits\n",
    "        return torch.sigmoid(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aaf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_weights)\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "# Training loop with enhanced evaluation using ROC-AUC\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, protein_vec, label in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Use logits for BCEWithLogitsLoss\n",
    "        if isinstance(criterion, nn.BCEWithLogitsLoss):\n",
    "            out = model(data, protein_vec, data.batch, return_logits=True)\n",
    "        else:\n",
    "            out = model(data, protein_vec, data.batch)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate model using ROC-AUC score for better performance measurement\n",
    "    on potentially imbalanced datasets\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, protein_vec, label in loader:\n",
    "            out = model(data, protein_vec, data.batch)  # Always get probabilities for evaluation\n",
    "            all_probs.extend(out.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "            # Also calculate accuracy for reference\n",
    "            preds = (out > 0.5).float()\n",
    "            correct += (preds == label).sum().item()\n",
    "            total += label.size(0)\n",
    "    \n",
    "    # Calculate ROC-AUC score and accuracy\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    accuracy = correct / total\n",
    "    return auc, accuracy\n",
    "\n",
    "def calculate_class_weights(dataset):\n",
    "    \"\"\"Calculate class weights for handling imbalanced datasets\"\"\"\n",
    "    labels = [dataset[i][2].item() for i in range(len(dataset))]\n",
    "    class_counts = Counter(labels)\n",
    "    total_samples = len(labels)\n",
    "    \n",
    "    # Calculate weights inversely proportional to class frequency\n",
    "    weights = {}\n",
    "    for class_label, count in class_counts.items():\n",
    "        weights[class_label] = total_samples / (len(class_counts) * count)\n",
    "    \n",
    "    print(f\"Dataset class distribution: {dict(class_counts)}\")\n",
    "    print(f\"Calculated class weights: {weights}\")\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79555b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced training script with all advanced features\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset\n",
    "    dataset = DrugTargetDataset(\n",
    "        \"data/step6_training_pairs.csv\",\n",
    "        \"data/graphs/\",\n",
    "        \"data/step4_protein_onehot.csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Dataset loaded: {len(dataset)} samples\")\n",
    "    \n",
    "    # Calculate class weights for handling imbalance\n",
    "    class_weights = calculate_class_weights(dataset)\n",
    "    \n",
    "    # Create weighted loss function\n",
    "    pos_weight = torch.tensor([class_weights.get(1.0, 1.0) / class_weights.get(0.0, 1.0)])\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    print(f\"🎯 Using weighted BCE loss with pos_weight: {pos_weight.item():.3f}\")\n",
    "\n",
    "    # Split dataset\n",
    "    train_len = int(0.8 * len(dataset))\n",
    "    train_set, test_set = random_split(dataset, [train_len, len(dataset) - train_len])\n",
    "    train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=16)\n",
    "    \n",
    "    print(f\"📚 Training samples: {len(train_set)}\")\n",
    "    print(f\"🧪 Test samples: {len(test_set)}\")\n",
    "\n",
    "    # Initialize model and training components\n",
    "    model = DrugTargetModel(in_channels=6, hidden_dim=128, protein_dim=20)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001, restore_best_weights=True)\n",
    "    \n",
    "    # Training tracking\n",
    "    best_auc = 0.0\n",
    "    training_history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'test_auc': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "\n",
    "    print(\"\\n🚀 Starting enhanced training...\")\n",
    "    print(\"📈 Metrics: Loss (↓), ROC-AUC (↑ 1.0=perfect), Accuracy (↑)\")\n",
    "    print(\"🛑 Early stopping: patience=5, min_delta=0.001\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for epoch in range(1, 51):  # Increased max epochs\n",
    "        # Training phase\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        test_auc, test_accuracy = evaluate(model, test_loader)\n",
    "        \n",
    "        # Store history\n",
    "        training_history['epoch'].append(epoch)\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['test_auc'].append(test_auc)\n",
    "        training_history['test_accuracy'].append(test_accuracy)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch:02d} | Loss: {train_loss:.4f} | AUC: {test_auc:.4f} | Acc: {test_accuracy:.4f}\", end=\"\")\n",
    "        \n",
    "        # Check for best model\n",
    "        if test_auc > best_auc:\n",
    "            best_auc = test_auc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_auc': best_auc,\n",
    "                'training_history': training_history\n",
    "            }, 'best_drug_target_model.pth')\n",
    "            print(\" 🌟 NEW BEST!\")\n",
    "        else:\n",
    "            print()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(test_auc, model):\n",
    "            print(f\"\\n🛑 Early stopping triggered at epoch {epoch}\")\n",
    "            print(f\"🔄 Restored best weights from epoch with AUC: {early_stopping.best_score:.4f}\")\n",
    "            break\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"✅ Training completed!\")\n",
    "    print(f\"🏆 Best ROC-AUC achieved: {best_auc:.4f}\")\n",
    "    print(f\"💾 Best model saved as: 'best_drug_target_model.pth'\")\n",
    "    \n",
    "    # Final evaluation on test set with best model\n",
    "    final_auc, final_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"🎯 Final test performance:\")\n",
    "    print(f\"   ROC-AUC: {final_auc:.4f}\")\n",
    "    print(f\"   Accuracy: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Save training history\n",
    "    import json\n",
    "    with open('training_history.json', 'w') as f:\n",
    "        json.dump(training_history, f, indent=2)\n",
    "    print(f\"📊 Training history saved as: 'training_history.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize training progress (uncomment to use)\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Load training history\n",
    "with open('training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Create plots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax1.plot(history['epoch'], history['train_loss'], 'b-', linewidth=2)\n",
    "ax1.set_title('Training Loss Over Time')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: ROC-AUC\n",
    "ax2.plot(history['epoch'], history['test_auc'], 'g-', linewidth=2)\n",
    "ax2.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Random (0.5)')\n",
    "ax2.set_title('ROC-AUC Score Over Time')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('AUC')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Accuracy\n",
    "ax3.plot(history['epoch'], history['test_accuracy'], 'orange', linewidth=2)\n",
    "ax3.set_title('Test Accuracy Over Time')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_progress.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"📈 Training visualization saved as 'training_progress.png'\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
